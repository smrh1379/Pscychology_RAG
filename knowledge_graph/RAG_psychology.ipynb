{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtnP3MR6xdEE"
      },
      "source": [
        "# ***Import Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FSLE7S9wNZb",
        "outputId": "62c4d28e-a260-41db-850a-e30e27562dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ifEf0vexyNm",
        "outputId": "ceed16fb-711c-4773-d8c6-44288f32064a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.5/293.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.3.1\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.58-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.10.58 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.58-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.31-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.58->llama-index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.6.7)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.58->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.58->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.14.1)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.58->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.58->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.58->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.58->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.58->llama-index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.58->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.58->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.58->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.58->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.58->llama-index) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.58->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.58->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.58->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.58->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.58->llama-index) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.58->llama-index) (1.16.0)\n",
            "Downloading llama_index-0.10.58-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_core-0.10.58-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.31-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, dirtyjson, deprecated, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed deprecated-1.2.14 dirtyjson-1.0.8 llama-cloud-0.0.11 llama-index-0.10.58 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.58 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.31 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j\n",
        "!pip install pypdf\n",
        "!pip install tiktoken\n",
        "!pip install sentence-transformers\n",
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzeYQ7-mx_IU",
        "outputId": "0a188a4c-fc6a-4211-9171-2505c09c0b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rapidocr-onnxruntime\n",
            "  Downloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.10.0.84)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (6.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
            "Collecting onnxruntime>=1.7.0 (from rapidocr-onnxruntime)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
            "Downloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclipper, humanfriendly, coloredlogs, onnxruntime, rapidocr-onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.1 pyclipper-1.3.0.post5 rapidocr-onnxruntime-1.3.24\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidocr-onnxruntime\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import openai\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYlsDojL2fv0"
      },
      "source": [
        "# ***Data Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ZbJuKC2Z72",
        "outputId": "fb2d65f0-b19a-4986-8491-07d798f3a940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13stHs8NzNO_MZ20VWw2IT3yvndKt2MUx\n",
            "To: /content/DSM5.txt\n",
            "100%|██████████| 3.15M/3.15M [00:00<00:00, 64.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VmmNHMt9FLqJu_FllQU5Ck6PF8CUabyY\n",
            "To: /content/DSM5.pdf\n",
            "100%|██████████| 32.0M/32.0M [00:00<00:00, 41.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# data txt url\n",
        "id = \"13stHs8NzNO_MZ20VWw2IT3yvndKt2MUx\"\n",
        "output = \"DSM5.txt\"\n",
        "gdown.download(id=id, output=output)\n",
        "\n",
        "txt_path = \"/content/DSM5.txt\"\n",
        "\n",
        "id = \"1VmmNHMt9FLqJu_FllQU5Ck6PF8CUabyY\"\n",
        "output = \"DSM5.pdf\"\n",
        "gdown.download(id=id, output=output)\n",
        "\n",
        "pdf_path = \"/content/DSM5.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLtmYp2AdfSJ"
      },
      "source": [
        "## ***Vector Database***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRvJQM8dHqzI"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(pdf_path)\n",
        "doc = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEWxZKLQI4Vv"
      },
      "outputs": [],
      "source": [
        "# split documents into text and embeddings\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "   chunk_size=1000,\n",
        "   chunk_overlap=150\n",
        ")\n",
        "chunks = text_splitter.split_documents(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPvxFEUPJQs9",
        "outputId": "03ab1f5d-4da8-4453-97ab-c3d12708714f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/DSM5.pdf', 'page': 243}, page_content='Differential Diagnosis\\nNormative shyness. Shyness (i.e., social reticence) is a common personality trait and is \\nnot by itself pathological. In some societies, shyness is even evaluated positively. How\\xad\\never, when there is a significant adverse impact on social, occupational, and other impor\\xad\\ntant areas of functioning, a diagnosis of social anxiety disorder should be considered, and \\nwhen full diagnostic criteria for social anxiety disorder are met, the disorder should be di\\xad\\nagnosed. Only a minority (12%) of self-identified shy individuals in the United States have \\nsymptoms that meet diagnostic criteria for social anxiety disorder.\\nAgoraphobia. Individuals with agoraphobia may fear and avoid social situations (e.g., go\\xad\\ning to a movie) because escape might be difficult or help might not be available in the event of \\nincapacitation or panic-like symptoms, whereas individuals with social anxiety disorder are')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKDyNlPJE1u",
        "outputId": "992f4a42-d486-4f94-8635-d06efd55aef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"harmonization. However, given that adoption of the ICD-9-CM coding system will remain \\nat the time of the DSM-5 release, it will be necessary to use the ICD-9-CM codes. Further\\xad\\nmore, given that DSM-5's organizational structure reflects the anticipated structure of \\nICD-11, the eventual ICD-11 codes will follow the sequential order of diagnoses in the \\nDSM-5 chapter structure more closely. At present, both the ICD-9-CM and the ICD-IO-CM \\ncodes have been indicated for each disorder. These codes will not be in sequential order \\nthroughout the manual because they were assigned to complement earlier organizational \\nstructures.\\nDimensional Approach to Diagnosis\\nStructural problems rooted in the basic design of the previous DSM classification, con\\xad\\nstructed of a large number of narrow diagnostic categories, have emerged in both clinical \\npractice and research. Relevant evidence comes from diverse sources, including shidies of\",\n",
              " 'practice and research. Relevant evidence comes from diverse sources, including shidies of \\ncomorbidity and the substantial need for not otherwise specified diagnoses, which repre\\xad\\nsent the majority of diagnoses in areas such as eating disorders, personality disorders, and \\nautism spectrum disorder. Studies of both genetic and environmental risk factors, whether \\nbased on twin designs, familial transmission, or molecular analyses, also raise concerns \\nabout the categorical structure of the DSM system. Because the previous DSM approach \\nconsidered each diagnosis as categorically separate from health and from other diagnoses, \\nit did not capture the widespread sharing of symptoms and risk factors across many dis\\xad\\norders that is apparent in studies of comorbidity. Earlier editions of DSM focused on ex\\xad\\ncluding false-positive results from diagnoses; thus, its categories were overly narrow, as is \\napparent from the widespread need to use NOS diagnoses. Indeed, the once plausible goal',\n",
              " 'apparent from the widespread need to use NOS diagnoses. Indeed, the once plausible goal \\nof identifying homogeneous populations for treatment and research resulted in narrow di\\xad\\nagnostic categories that did not capture clinical reality, symptom heterogeneity within dis\\xad\\norders, and significant sharing of symptoms across multiple disorders. The historical \\naspiration of achieving diagnostic homogeneity by progressive subtyping within disorder \\ncategories no longer is sensible; like most common human ills, mental disorders are het\\xad\\nerogeneous at many levels, ranging from genetic risk factors to symptoms.\\nRelated to recommendations about alterations in the chapter structure of DSM-5, mem\\xad\\nbers of the diagnostic spectra study group examined whether scientific validators could \\ninform possible new groupings of related disorders within the existing categorical frame\\xad\\nwork. Eleven such indicators were recommended for this purpose: shared neural sub\\xad',\n",
              " 'work. Eleven such indicators were recommended for this purpose: shared neural sub\\xad\\nstrates, family traits, genetic risk factors, specific environmental risk factors, biomarkers, \\ntemperamental antecedents, abnormalities of emotional or cognitive processing, symptom \\nsimilarity, course of illness, high comorbidity, and shared treatment response. These indi\\xad\\ncators served as empirical guidelines to inform decision making by the work groups and \\nthe task force about how to cluster disorders to maximize their validity and clinical utility.\\nA series of papers was developed and published in a prominent international journal \\n(Psychological Medicine,  Vol. 39,2009) as part of both the DSM-5 and the ICD-11 develop\\xad\\nmental processes to document that such validators were most useful for suggesting large \\ngroupings of disorders rather than for \"validating\" individual disorder diagnostic criteria. \\nThe regrouping of mental disorders in DSM-5 is intended to enable future research to en-',\n",
              " 'hance understanding of disease origins and pathophysiological commonalities between \\ndisorders and provide a base for future replication wherein data can be reanalyzed over \\ntime to continually assess validity. Ongoing revisions of DSM-5 will make it a \\'\\'living doc\\xad\\nument,\" adaptable to future discoveries in neurobiology, genetics, and epidemiology.\\nOn the basis of the published findings of this common DSM-5 and ICD-11 analysis, it \\nwas demonstrated that clustering of disorders according to what has been termed internal\\xad\\nizing  and externalizing factors represents an empirically supported framework. Within both \\nthe internalizing group (representing disorders with prominent anxiety, depressive, and \\nsomatic symptoms) and the externalizing group (representing disorders with prominent \\nimpulsive, disruptive conduct, and substance use symptoms), the sharing of genetic and \\nenvironmental risk factors, as shown by twin studies, likely explains much of the system\\xad',\n",
              " 'environmental risk factors, as shown by twin studies, likely explains much of the system\\xad\\natic comorbidities seen in both clinical and community samples. The adjacent placement of \\n\"internalizing disorders,\" characterized by depressed mood, anxiety, and related physio\\xad\\nlogical and cognitive symptoms, should aid in developing new diagnostic approaches, in\\xad\\ncluding dimensional approaches, while facilitating the identification of biological markers. \\nSimilarly, adjacencies of the \"externalizing group,\" including disorders exhibiting antiso\\xad\\ncial behaviors, conduct disturbances, addictions, and impulse-control disorders, should en\\xad\\ncourage advances in identifying diagnoses, markers, and underlying mechanisms.\\nDespite the problem posed by categorical diagnoses, the DSM-5 Task Force recognized \\nthat it is premature scientifically to propose alternative definitions for most disorders. The \\norganizational structure is meant to serve as a bridge to new diagnostic approaches with\\xad',\n",
              " 'organizational structure is meant to serve as a bridge to new diagnostic approaches with\\xad\\nout disrupting current clinical practice or research. With support from DSM-associated \\ntraining materials, the National Institutes of Health other funding agencies, and scientific \\npublications, the more dimensional DSM-5 approach and organizational structure can fa\\xad\\ncilitate research across current diagnostic categories by encouraging broad investigations \\nwithin the proposed chapters and across adjacent chapters. Such a reformulation of re\\xad\\nsearch goals should also keep DSM-5 central to the development of dimensional approaches \\nto diagnosis that will likely supplement or supersede current categorical approaches in \\ncoming years.\\nDevelopmental and Lifespan Considerations\\nTo improve clinical utility, DSM-5 is organized on developmental and lifespan consider\\xad\\nations. It begins with diagnoses thought to reflect developmental processes that manifest',\n",
              " 'ations. It begins with diagnoses thought to reflect developmental processes that manifest \\nearly in life (e.g., neurodevelopmental and schizophrenia spectrum and other psychotic \\ndisorders), followed by diagnoses that more commonly manifest in adolescence and \\nyoung adulthood (e.g., bipolar, depressive, and anxiety disorders), and ends with diagno\\xad\\nses relevant to adulthood and later life (e.g., neurocognitive disorders). A similar approach \\nhas been taken, where possible, within each chapter. This organizational structure facili\\xad\\ntates the comprehensive use of lifespan information as a way to assist in diagnostic deci\\xad\\nsion making.\\nThe proposed organization of chapters of DSM-5, after the neurodevelopmental disor\\xad\\nders, is based on groups of internalizing (emotional and somatic) disorders, externalizing \\ndisorders, neurocognitive disorders, and other disorders. It is hoped that this organization',\n",
              " 'disorders, neurocognitive disorders, and other disorders. It is hoped that this organization \\nwill encourage further study of underlying pathophysiological processes that give rise to \\ndiagnostic comorbidity and symptom heterogeneity. Furthermore, by arranging disorder \\nclusters to mirror clinical reality, DSM-5 should facilitate identification of potential diag\\xad\\nnoses by non-mental health specialists, such as primary care physicians.\\nThe organizational structure of DSM-5, along with ICD harmonization, is designed to \\nprovide better and more flexible diagnostic concepts for the next epoch of research and to \\nserve as a useful guide to clinicians in explaining to patients why they might have received \\nmultiple diagnoses or why they might have received additional or altered diagnoses over \\ntheir lifespan.',\n",
              " 'Cultural Issues\\nMental disorders are defined in relation to cultural, social, and familial norms and values. \\nCulture provides interpretive frameworks that shape the experience and expression of the \\nsymptoms, signs, and behaviors that are criteria for diagnosis. Culture is transmitted, re\\xad\\nvised, and recreated within the family and other social systems and institutions. Diagnostic \\nassessment must therefore consider whether an individual\\'s experiences, symptoms, and \\nbehaviors differ from sociocultural norms and lead to difficulties in adaptation in the cul\\xad\\ntures of origin and in specific social or familial contexts. Key aspects of culture relevant to di\\xad\\nagnostic classification and assessment have been considered in the development of DSM-5.\\nIn Section III, the \"Cultural Formulation\" contains a detailed discussion of culture and \\ndiagnosis in DSM-5, including tools for in-depth cultural assessment. In the Appendix, the']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_array = []\n",
        "for i, row in enumerate(chunks):\n",
        "  context_array.append(row.page_content)\n",
        "\n",
        "context_array[150:160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWd6jzxfNda8",
        "outputId": "c2bd12a8-9de8-4886-fd44-1fe7acaf3950"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"harmonization. However, given that adoption of the ICD-9-CM coding system will remain at the time of the DSM-5 release, it will be necessary to use the ICD-9-CM codes. Further more, given that DSM-5's organizational structure reflects the anticipated structure of ICD-11, the eventual ICD-11 codes will follow the sequential order of diagnoses in the DSM-5 chapter structure more closely. At present, both the ICD-9-CM and the ICD-IO-CM codes have been indicated for each disorder. These codes will not be in sequential order throughout the manual because they were assigned to complement earlier organizational structures. Dimensional Approach to Diagnosis Structural problems rooted in the basic design of the previous DSM classification, con structed of a large number of narrow diagnostic categories, have emerged in both clinical practice and research. Relevant evidence comes from diverse sources, including shidies of\",\n",
              " 'practice and research. Relevant evidence comes from diverse sources, including shidies of comorbidity and the substantial need for not otherwise specified diagnoses, which repre sent the majority of diagnoses in areas such as eating disorders, personality disorders, and autism spectrum disorder. Studies of both genetic and environmental risk factors, whether based on twin designs, familial transmission, or molecular analyses, also raise concerns about the categorical structure of the DSM system. Because the previous DSM approach considered each diagnosis as categorically separate from health and from other diagnoses, it did not capture the widespread sharing of symptoms and risk factors across many dis orders that is apparent in studies of comorbidity. Earlier editions of DSM focused on ex cluding false-positive results from diagnoses; thus, its categories were overly narrow, as is apparent from the widespread need to use NOS diagnoses. Indeed, the once plausible goal',\n",
              " 'apparent from the widespread need to use NOS diagnoses. Indeed, the once plausible goal of identifying homogeneous populations for treatment and research resulted in narrow di agnostic categories that did not capture clinical reality, symptom heterogeneity within dis orders, and significant sharing of symptoms across multiple disorders. The historical aspiration of achieving diagnostic homogeneity by progressive subtyping within disorder categories no longer is sensible; like most common human ills, mental disorders are het erogeneous at many levels, ranging from genetic risk factors to symptoms. Related to recommendations about alterations in the chapter structure of DSM-5, mem bers of the diagnostic spectra study group examined whether scientific validators could inform possible new groupings of related disorders within the existing categorical frame work. Eleven such indicators were recommended for this purpose: shared neural sub',\n",
              " 'work. Eleven such indicators were recommended for this purpose: shared neural sub strates, family traits, genetic risk factors, specific environmental risk factors, biomarkers, temperamental antecedents, abnormalities of emotional or cognitive processing, symptom similarity, course of illness, high comorbidity, and shared treatment response. These indi cators served as empirical guidelines to inform decision making by the work groups and the task force about how to cluster disorders to maximize their validity and clinical utility. A series of papers was developed and published in a prominent international journal (Psychological Medicine, Vol. 39,2009) as part of both the DSM-5 and the ICD-11 develop mental processes to document that such validators were most useful for suggesting large groupings of disorders rather than for \"validating\" individual disorder diagnostic criteria. The regrouping of mental disorders in DSM-5 is intended to enable future research to en-',\n",
              " 'hance understanding of disease origins and pathophysiological commonalities between disorders and provide a base for future replication wherein data can be reanalyzed over time to continually assess validity. Ongoing revisions of DSM-5 will make it a \\'\\'living doc ument,\" adaptable to future discoveries in neurobiology, genetics, and epidemiology. On the basis of the published findings of this common DSM-5 and ICD-11 analysis, it was demonstrated that clustering of disorders according to what has been termed internal izing and externalizing factors represents an empirically supported framework. Within both the internalizing group (representing disorders with prominent anxiety, depressive, and somatic symptoms) and the externalizing group (representing disorders with prominent impulsive, disruptive conduct, and substance use symptoms), the sharing of genetic and environmental risk factors, as shown by twin studies, likely explains much of the system',\n",
              " 'environmental risk factors, as shown by twin studies, likely explains much of the system atic comorbidities seen in both clinical and community samples. The adjacent placement of \"internalizing disorders,\" characterized by depressed mood, anxiety, and related physio logical and cognitive symptoms, should aid in developing new diagnostic approaches, in cluding dimensional approaches, while facilitating the identification of biological markers. Similarly, adjacencies of the \"externalizing group,\" including disorders exhibiting antiso cial behaviors, conduct disturbances, addictions, and impulse-control disorders, should en courage advances in identifying diagnoses, markers, and underlying mechanisms. Despite the problem posed by categorical diagnoses, the DSM-5 Task Force recognized that it is premature scientifically to propose alternative definitions for most disorders. The organizational structure is meant to serve as a bridge to new diagnostic approaches with',\n",
              " 'organizational structure is meant to serve as a bridge to new diagnostic approaches with out disrupting current clinical practice or research. With support from DSM-associated training materials, the National Institutes of Health other funding agencies, and scientific publications, the more dimensional DSM-5 approach and organizational structure can fa cilitate research across current diagnostic categories by encouraging broad investigations within the proposed chapters and across adjacent chapters. Such a reformulation of re search goals should also keep DSM-5 central to the development of dimensional approaches to diagnosis that will likely supplement or supersede current categorical approaches in coming years. Developmental and Lifespan Considerations To improve clinical utility, DSM-5 is organized on developmental and lifespan consider ations. It begins with diagnoses thought to reflect developmental processes that manifest',\n",
              " 'ations. It begins with diagnoses thought to reflect developmental processes that manifest early in life (e.g., neurodevelopmental and schizophrenia spectrum and other psychotic disorders), followed by diagnoses that more commonly manifest in adolescence and young adulthood (e.g., bipolar, depressive, and anxiety disorders), and ends with diagno ses relevant to adulthood and later life (e.g., neurocognitive disorders). A similar approach has been taken, where possible, within each chapter. This organizational structure facili tates the comprehensive use of lifespan information as a way to assist in diagnostic deci sion making. The proposed organization of chapters of DSM-5, after the neurodevelopmental disor ders, is based on groups of internalizing (emotional and somatic) disorders, externalizing disorders, neurocognitive disorders, and other disorders. It is hoped that this organization',\n",
              " 'disorders, neurocognitive disorders, and other disorders. It is hoped that this organization will encourage further study of underlying pathophysiological processes that give rise to diagnostic comorbidity and symptom heterogeneity. Furthermore, by arranging disorder clusters to mirror clinical reality, DSM-5 should facilitate identification of potential diag noses by non-mental health specialists, such as primary care physicians. The organizational structure of DSM-5, along with ICD harmonization, is designed to provide better and more flexible diagnostic concepts for the next epoch of research and to serve as a useful guide to clinicians in explaining to patients why they might have received multiple diagnoses or why they might have received additional or altered diagnoses over their lifespan.',\n",
              " 'Cultural Issues Mental disorders are defined in relation to cultural, social, and familial norms and values. Culture provides interpretive frameworks that shape the experience and expression of the symptoms, signs, and behaviors that are criteria for diagnosis. Culture is transmitted, re vised, and recreated within the family and other social systems and institutions. Diagnostic assessment must therefore consider whether an individual\\'s experiences, symptoms, and behaviors differ from sociocultural norms and lead to difficulties in adaptation in the cul tures of origin and in specific social or familial contexts. Key aspects of culture relevant to di agnostic classification and assessment have been considered in the development of DSM-5. In Section III, the \"Cultural Formulation\" contains a detailed discussion of culture and diagnosis in DSM-5, including tools for in-depth cultural assessment. In the Appendix, the']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    # Remove unwanted characters\n",
        "    text = text.replace('\\n', ' ').replace('\\xad', '')\n",
        "    # Fix broken words by removing extraneous spaces\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "context_array_cleaned = []\n",
        "for i, chunk in enumerate(context_array):\n",
        "    context_array_cleaned.append(clean_text(chunk))\n",
        "\n",
        "context_array_cleaned[150:160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQlPSMOJOQRc"
      },
      "outputs": [],
      "source": [
        "# Type 1\n",
        "\n",
        "\n",
        "def generate_embeddings(text_chunks):\n",
        "    embeddings = []\n",
        "    for chunk in text_chunks:\n",
        "        response = openai.Embedding.create(\n",
        "            input=chunk,\n",
        "            model=\"text-embedding-ada-002\"\n",
        "        )\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "embeddings = generate_embeddings(context_array_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFy03X6WySc3",
        "outputId": "bc16fc2a-3353-401c-9a5c-476336080c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Type 2\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "# Generate embeddings\n",
        "def generate_embeddings(text_chunks):\n",
        "    embeddings = model.encode(text_chunks, convert_to_tensor=True, device=device)\n",
        "    return embeddings\n",
        "\n",
        "embeddings = generate_embeddings(context_array_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKu0g0rC1eXt",
        "outputId": "52bd8a12-3ea6-4d7d-ff4a-8b0956e9ee38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3996, 384]), 3996)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.shape, len(context_array_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdpFwpiad_IH"
      },
      "source": [
        "## ***Knowledge Graph***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaYIBxuUeEeD",
        "outputId": "e06dc325-2be2-4afd-9618-d2edcc7fdfd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:153: UserWarning: Unknown PDF Filter!\n",
            "  warnings.warn(\"Unknown PDF Filter!\")\n"
          ]
        }
      ],
      "source": [
        "# from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(pdf_path,extract_images=True)\n",
        "doc = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "texts = text_splitter.split_documents(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "s6WsYazi_Led"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "texts = text_splitter.split_documents(doc[59:919])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbB-PJdB1pOK",
        "outputId": "84d755bd-474c-4e16-da1a-37c18c935102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "858"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBfSjw6F2rM_",
        "outputId": "9ac0b44b-901c-4ad1-f599-d864cbeb990b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/DSM5.pdf', 'page': 209}, page_content='2. Marked irritability or anger or increased interpersonal conflicts. 3. Marked depressed mood, feelings of hopelessness, or self-deprecating thoughts. 4. Marked anxiety, tension, and/or feelings of being keyed up or on edge. C. One (or more) of the following symptoms must additionally be present, to reach a total of five symptoms when combined with symptoms from Criterion B above. 1. Decreased interest in usual activities (e.g., work, school, friends, hobbies). 2. Subjective difficulty in concentration. 3. Lethargy, easy fatigability, or marked lack of energy. 4. Marked change in appetite; overeating; or specific food cravings. 5. Hypersomnia or insomnia. 6. A sense of being ovenwhelmed or out of control. 7. Physical symptoms such as breast tenderness or swelling, joint or muscle pain, a sensation of “ bloating,” or weight gain. Note: The symptoms in Criteria A-C must have been met for most menstrual cycles that occurred in the preceding year. D. The symptoms are associated with clinically significant distress or interference with work, school, usual social activities, or relationships with others (e.g., avoidance of so cial activities; decreased productivity and efficiency at work, school, or home). E. The disturbance is not merely an exacerbation of the symptoms of another disorder, such as major depressive disorder, panic disorder, persistent depressive disorder (dysthymia), or a personality disorder (although it may co-occur with any of these dis orders). F. Criterion A should be confirmed by prospective daily ratings during at least two symptom atic cycles. (Note: The diagnosis may be made provisionally prior to this confirmation.) G. The symptoms are not attributable to the physiological effects of a substance (e.g., a drug of abuse, a medication, other treatment) or another medical condition (e.g., hy perthyroidism). Recording Procedures If symptoms have not been confirmed by prospective daily ratings of at least two symp tomatic cycles, \"provisional\" should be noted after the name of the diagnosis (i.e., \"pre menstrual dysphoric disorder, provisional\"). Diagnostic Features The essential features of premenstrual dysphoric disorder are the expression of mood la bility, irritability, dysphoria, and anxiety symptoms that occur repeatedly during the pre menstrual phase of the cycle and remit around the onset of menses or shortly thereafter. These symptoms may be accompanied by behavioral and physical symptoms. Symptoms must have occurred in most of the menstrual cycles during the past year and must have an adverse effect on work or social functioning. The intensity and/or expressivity of the ac companying symptoms may be closely related to social and cultural background charac teristics of the affected female, family perspectives, and more specific factors such as religious beliefs, social tolerance, and female gender role issues. Typically, symptoms peak around the time of the onset of menses. Although it is not uncommon for symptoms to linger into the first few days of menses, the individual must have a symptom-free period in the follicular phase after the menstrual period begins. While the core symptoms include mood and anxiety symptoms, behavioral and somatic symptoms commonly also occur. However, the presence of physical and/or behavioral symptoms in the absence of mood and/or anxious symptoms is not sufficient for a diag')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    # Remove unwanted characters\n",
        "    text = text.replace('\\n', ' ').replace('\\xad', '')\n",
        "    # Fix broken words by removing extraneous spaces\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "for i, row in enumerate(texts):\n",
        "  texts[i].page_content = clean_text(row.page_content)\n",
        "\n",
        "texts[150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foMOg0qhgI1v",
        "outputId": "79bfb676-bcc7-4c50-c4e3-b16a012de4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of chunks is 858\n"
          ]
        }
      ],
      "source": [
        "print(f'number of chunks is {len(texts)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEiComcP1dvJ",
        "outputId": "0ee76204-05f9-4981-e622-6ad3e138ceb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:225: UserWarning: WARNING! stream is not default parameter.\n",
            "                stream was transferred to model_kwargs.\n",
            "                Please confirm that stream is what you intended.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "import openai\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Load environment varaiable for OpenAI API key\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", stream=False)\n",
        "\n",
        "# Extract Knowledge Graph\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(texts)\n",
        "graph.add_graph_documents(graph_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gJha9tXsC9Rd"
      },
      "outputs": [],
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "import os\n",
        "\n",
        "os.environ[\"NEO4J_URI\"] = \"bolt://18.207.208.98:7687\"\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"february-weaves-offices\"\n",
        "\n",
        "graph = Neo4jGraph()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wLtmYp2AdfSJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
